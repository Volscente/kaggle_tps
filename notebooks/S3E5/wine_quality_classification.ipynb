{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c014bbe-11c8-4563-a320-8a8391009048",
   "metadata": {},
   "source": [
    "# Wine Quality Classification\n",
    "\n",
    "The notebook is intended to develop & validate a model for multi-class classification of the Wine Quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3258c-939a-402b-b46f-19a39a7f9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore Scikit-Learn Convergence Warning\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cb18b-3ce5-4f9e-9113-99b5148843c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Seaborn theme parameters\n",
    "theme_parameters =  {\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "    'grid.alpha':0.3,\n",
    "    'figure.figsize': (16, 6),\n",
    "    'font.family': 'Andale Mono',\n",
    "    'axes.titlesize': 24,\n",
    "    'figure.facecolor': '#E5E8E8',\n",
    "    'axes.facecolor': '#E5E8E8'\n",
    "}\n",
    "\n",
    "# Set the theme\n",
    "sns.set_theme(style='whitegrid',\n",
    "              palette=sns.color_palette('deep'), \n",
    "              rc=theme_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530593f6-ab4a-4956-b9cb-e18ff93147d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook's variables\n",
    "train_data_path = os.path.join('./../../data/S3E5/wine_quality_train.csv')\n",
    "test_data_path = os.path.join('./../../data/S3E5/wine_quality_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec46d54-938f-4611-8ef7-a6ab5429167f",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a5cd5-fe09-4373-9c82-2e18fed307f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79337ab2-0fc5-41d9-a863-82a37adf819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a540c-9e69-43cb-8bd9-907cdacca751",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf171db9-4148-4df8-ba5e-c06db140279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3982530-599d-4870-9401-2ec835f9f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110baa6-8a5f-476b-8d40-48bfb5661a22",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c821d-b3cd-4a4e-9c69-38f61a5f0ef8",
   "metadata": {},
   "source": [
    "## Train Feature & Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230a7bc-0567-41a7-a57e-4278835bb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histograms of each feature\n",
    "figure, ax = plt.subplots(3, 4, figsize=(16, 9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Fetch the data to plot (exclude the 'id' column)\n",
    "for index, column_name in enumerate(train_data.columns[1:]):\n",
    "    \n",
    "    # Plot data\n",
    "    sns.histplot(data=train_data[column_name], \n",
    "                 ax=ax[index])\n",
    "    \n",
    "    ax[index].set_title(column_name, \n",
    "                        fontsize=14, \n",
    "                        fontweight='bold')\n",
    "    \n",
    "    ax[index].tick_params(labelrotation=45)\n",
    "    \n",
    "plt.suptitle('Feature & Label Distrubtion', \n",
    "             fontsize=20)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74dcfa9-fbbb-4585-8368-ca9313f80bbd",
   "metadata": {},
   "source": [
    "The following features have a skewed distribution:\n",
    "- `fixed acidity`\n",
    "- `citric acid`\n",
    "- `residual sugar`\n",
    "- `free sulfur dioxide`\n",
    "- `total sulfur dioxide`\n",
    "- `sulphates`\n",
    "- `alcohol`\n",
    "\n",
    "It would be useful to use the Z-Score Outliers Filter.\n",
    "<br>\n",
    "\n",
    "In addition, it is possible to see that the label classes 3, 4 and 8 do not have a lots of records. That is an imbalanced data problem. Consider to use a Stratified K-Fold during the training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ceb01b-fef2-4db1-8894-99a84ae0f436",
   "metadata": {},
   "source": [
    "## Train Feature Distribution per Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0e56d-d4c4-4338-8b36-396bb639080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the box plot of each feature per label\n",
    "figure, ax = plt.subplots(3, 4, figsize=(16, 12))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Fetch the data to plot (exclude the 'id' column and 'quality' column)\n",
    "for index, column_name in enumerate(train_data.columns[1:-1]):\n",
    "    \n",
    "    # Plot data\n",
    "    sns.boxplot(data=train_data,\n",
    "                x='quality',\n",
    "                y=column_name,\n",
    "                ax=ax[index])\n",
    "    \n",
    "        \n",
    "# Remove the empty subplot\n",
    "figure.delaxes(ax[-1])\n",
    "\n",
    "# Set title plot\n",
    "plt.suptitle('Feature Distrubtion per Label', \n",
    "             fontsize=20, \n",
    "             fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1d5af-7de0-457e-a65d-790f7df86929",
   "metadata": {},
   "source": [
    "There is a positive non-linear relationship between the following features and the `Quality`:\n",
    "- `sulphates`\n",
    "- `alcohol`\n",
    "\n",
    "Thre is a negative non-linear relationship between the following features the the `Quality`:\n",
    "- `voltatile acidity`\n",
    "- `density`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc648e74-c3f1-4e37-9dca-7ebb9cf7bae2",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294063ca-ce04-4340-842f-84342fba0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = train_data.iloc[:, 1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ad9c8-0402-474c-9f2f-f8c83bbf1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "correlation_mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d16a7-7ede-45a9-b434-5173522fe2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define figure and axis\n",
    "figure, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot the correlation matrix\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=correlation_mask, \n",
    "            cmap='mako',\n",
    "            vmax=1.0, \n",
    "            vmin=-1.0, \n",
    "            center=0, \n",
    "            square=True, \n",
    "            linewidths=.5, \n",
    "            annot=True,\n",
    "            annot_kws={'fontsize': 8},\n",
    "            cbar_kws={\"shrink\":.8, 'orientation':'vertical'})\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Pearson Correlation', \n",
    "             fontsize=20, \n",
    "             fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877b3aa-4f29-4f31-9e5f-0f541b671d88",
   "metadata": {},
   "source": [
    "The following features show a significant positive correlation:\n",
    "- `citric acid` and `fixed acidity`\n",
    "- `density` and `fixed acidity`\n",
    "- `total sulfur dioxide` and `free sulfur dioxide`\n",
    "\n",
    "The following features show a significant negative correlation:\n",
    "- `citric acid` and `volatile acidity`\n",
    "- `pH` and `fixed acidity`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90aa6c-058f-4515-b1eb-a9c1468b0baa",
   "metadata": {},
   "source": [
    "## Train vs Test Feature & Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208ad30-0376-4b7d-93fc-cf43dfabba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the KDE of each feature\n",
    "figure, ax = plt.subplots(3, 4, figsize=(16, 12))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Fetch the data to plot (exclude the 'id' and 'quality' columns)\n",
    "for index, column_name in enumerate(train_data.columns[1:-1]):\n",
    "    \n",
    "    # Plot data\n",
    "    sns.kdeplot(data=train_data[column_name],\n",
    "                label='Train',\n",
    "                ax=ax[index])\n",
    "    \n",
    "    sns.kdeplot(data=test_data[column_name],\n",
    "                label='Test',\n",
    "                ax=ax[index])\n",
    "    \n",
    "    ax[index].set_title(column_name, fontsize=14)\n",
    "    \n",
    "    ax[index].tick_params(labelrotation=45)\n",
    "    \n",
    "    # Retrieve legend information\n",
    "    handles = ax[index].get_legend_handles_labels()[0]\n",
    "    labels = ax[index].get_legend_handles_labels()[1]\n",
    "    ax[index].legend().remove()\n",
    "    \n",
    "# Remove the empty subplot\n",
    "figure.delaxes(ax[-1])\n",
    "\n",
    "# Set the legend\n",
    "figure.legend(handles, \n",
    "              labels, \n",
    "              loc='upper center', \n",
    "              bbox_to_anchor=(0.5, 1.03), \n",
    "              fontsize=12,\n",
    "              ncol=2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee940156-c684-437a-815f-e8b182cdb824",
   "metadata": {},
   "source": [
    "There are no strong differences between the feature distribution of the train set and the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8217e-bf95-481c-9da9-2aadfc01a4b7",
   "metadata": {},
   "source": [
    "## Count Outliers with the Z-Score across Quality Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792fdd3-21de-431e-a300-49ace0f848a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Z-Score for the feature columns across 'quality' classes\n",
    "z_scores = train_data.iloc[:, 1:-1].groupby(train_data['quality'], \n",
    "                                            group_keys=True).apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cbeb3-0ebe-4d8a-af4b-2ac6dfa428b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider as an 'outlier' every records with a Z-Score bigger than 2 SDs in absolute value terms\n",
    "outliers = z_scores.abs().ge(2).groupby(z_scores.index.get_level_values(0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65971e-78e8-487a-95b7-f69366704ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outlisers per feature across 'quality' classes\n",
    "figure, ax = plt.subplots(3, 4, figsize=(16, 9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Fetch the data to plot (exclude the 'id' and 'quality' columns)\n",
    "for index, column_name in enumerate(outliers.columns):\n",
    "    \n",
    "    # Plot data\n",
    "    sns.barplot(data=outliers,\n",
    "                x=outliers.index,\n",
    "                y=column_name,\n",
    "                ax=ax[index])\n",
    "    \n",
    "    ax[index].set_title(column_name, fontsize=14)\n",
    "    \n",
    "    ax[index].tick_params(labelrotation=45)\n",
    "    \n",
    "# Remove the empty subplot\n",
    "figure.delaxes(ax[-1])\n",
    "\n",
    "# Set title plot\n",
    "plt.suptitle('Outliers Count', \n",
    "             fontsize=20, \n",
    "             fontweight='bold')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed4334-543f-49a7-ab0a-1211d4c08ca7",
   "metadata": {},
   "source": [
    "The quality classes 5, 6 and 7 show the highest amount of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da7bd1-f2b9-4ddd-b242-ae6b5f7022c2",
   "metadata": {},
   "source": [
    "## Train Feature Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16304d4-ed36-449b-99f2-c41f234a09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Pairplot between the features\n",
    "sns.pairplot(train_data.drop(columns=['Id', 'quality']),\n",
    "             kind=\"reg\",\n",
    "             diag_kind='kde',\n",
    "             plot_kws={'line_kws':{'color':'red'}},\n",
    "             corner=True)\n",
    "\n",
    "# Set title plot\n",
    "plt.suptitle('Train Feature Pairplot', \n",
    "             fontsize=20, \n",
    "             fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b41ce-1a7a-4697-a536-e1ab895617b8",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- Several numerical features present a right-skew distribution -> Use of a StandardScaler\n",
    "- `quality` target variable have imbalanced classes -> Use a Stratified K-Fold\n",
    "- Create a `sulphates for alcohol` feature through `sulphates` * `alcohol`\n",
    "- Create a `volatile acidity for density` feature through `volatile acidity` * `density`\n",
    "- Create a `sulphates over density` feature through `sulphates` / `density`\n",
    "- Create a `alcohol over density` feature through `alcohol` / `density`\n",
    "- Create a `sulphates over volatile acidity` feature through `sulphates` / `volatile acidity`\n",
    "- Create a `alcohol over volatile acidity` feature through `alcohol` / `volatile acidity`\n",
    "- Create a `citric acid for fixed acidity` feature through `citric acid` * `fixed acidity`\n",
    "- Create a `density for fixed acidity` feature through `density` * `fixed acidity`\n",
    "- Create a `total sulfur dioxide for free sulfur dioxide` feature through `total sulfur dioxide` * `free sulfur dioxide`\n",
    "- Create a `citric acid for volatile acidity` feature through `citric acid` * `volatile acidity`\n",
    "- Create a `pH for fixed acidity` feature through `pH` * `fixed acidity`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ade6a6-cd3b-4a3a-8b32-4a2cd91b5ca0",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3bb2d5-e977-41a7-9213-01f65681dbcf",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a63cb-d796-437e-b9e8-329dc7519d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_engineered_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a pre-defined set of engineered feature to the input DataFrame\n",
    "    \n",
    "    Args:\n",
    "        data Pandas.DataFrame input\n",
    "    \n",
    "    Returns;\n",
    "        data Pandas.DataFrame with additional engineered features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a `sulphates for alcohol` feature through `sulphates` * `alcohol`\n",
    "    data['sulphates for alcohol'] = round(data['sulphates'] * data['alcohol'], 2)\n",
    "    \n",
    "    # Create a `volatile acidity for density` feature through `volatile acidity` * `density`\n",
    "    data['volatile acidity for density'] = round(data['volatile acidity'] * data['density'], 2)\n",
    "    \n",
    "    # Create a `sulphates over density` feature through `sulphates` / `density`\n",
    "    data['sulphates over density'] = round(data['sulphates'] / data['density'], 2)\n",
    "    \n",
    "    # Create a `alcohol over density` feature through `alcohol` / `density`\n",
    "    data['alcohol over density'] = round(data['alcohol'] / data['density'], 2)\n",
    "    \n",
    "    # Create a `sulphates over volatile acidity` feature through `sulphates` / `volatile acidity`\n",
    "    data['sulphates over volatile acidity'] = round(data['sulphates'] / data['volatile acidity'], 2)\n",
    "    \n",
    "    # Create a `alcohol over volatile acidity` feature through `alcohol` / `volatile acidity`\n",
    "    data['alcohol over volatile acidity'] = round(data['alcohol'] / data['volatile acidity'], 2)\n",
    "    \n",
    "    # Create a `citric acid for fixed acidity` feature through `citric acid` * `fixed acidity`\n",
    "    data['citric acid for fixed acidity'] = round(data['citric acid'] * data['fixed acidity'], 2)\n",
    "    \n",
    "    # Create a `density for fixed acidity` feature through `density` * `fixed acidity`\n",
    "    data['density for fixed acidity'] = round(data['density'] * data['fixed acidity'], 2)\n",
    "    \n",
    "    # Create a `total sulfur dioxide for free sulfur dioxide` feature through `total sulfur dioxide` * `free sulfur dioxide`\n",
    "    data['total sulfur dioxide for free sulfur dioxide'] = round(data['total sulfur dioxide'] * data['free sulfur dioxide'], 2)\n",
    "    \n",
    "    # Create a `citric acid for volatile acidity` feature through `citric acid` * `volatile acidity`\n",
    "    data['citric acid for volatile acidity'] = round(data['citric acid'] * data['volatile acidity'], 2)\n",
    "    \n",
    "    # Create a `pH for fixed acidity` feature through `pH` * `fixed acidity`\n",
    "    data['pH for fixed acidity'] = round(data['pH'] * data['fixed acidity'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af102d17-ab63-4559-8637-ed18ee210fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the feature engineering\n",
    "compute_engineered_features(train_data)\n",
    "compute_engineered_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414bcd2-b664-4162-b21b-1b182262c41b",
   "metadata": {},
   "source": [
    "## Features and Labels Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f2070-cfac-42eb-9632-6269e08e765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels\n",
    "numerical_features = train_data.columns[1:12].tolist()\n",
    "\n",
    "numerical_engineered_featuers = train_data.columns[13:].tolist()\n",
    "\n",
    "labels = ['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f7a4b-bd8c-44a5-88b6-bcfbf33fbc3d",
   "metadata": {},
   "source": [
    "## Numerical Features Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd8e58-41f8-4805-b3ca-e64e8b5db72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features pipeline\n",
    "numerical_features_pipeline = Pipeline(steps=[\n",
    "    ('numerical_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c52e4-5da2-4bb9-8ef1-201c17fa87fb",
   "metadata": {},
   "source": [
    "## Bundle Data Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fe394-785c-48d0-9550-48d8739c2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunlde data preprocessing steps\n",
    "data_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical_preprocessing', \n",
    "         numerical_features_pipeline, \n",
    "         numerical_features + numerical_engineered_featuers),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f962c8-09a7-40e6-a87a-01584460b0cf",
   "metadata": {},
   "source": [
    "# Train & Test Split\n",
    "\n",
    "Not used with the Stratified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f086e05-348c-475c-b11b-47fc7ff6bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for the training set\n",
    "X = train_data[numerical_features + numerical_engineered_featuers]\n",
    "y = train_data[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0664be-a843-4ab1-9aeb-65a1f862a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the label\n",
    "label_encoder = LabelEncoder()\n",
    "y = pd.DataFrame({'quality': label_encoder.fit_transform(np.ravel(y))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b1b56-85ef-46a0-8da4-f74ab7412efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774ebc8-ea16-4fad-93b8-8cb5466fe041",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797c81d-d45c-4c0c-b6ec-c5eac75800eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used metrics\n",
    "metrics = ['Cohen Kappa Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28550452-f256-4f8f-8037-52dd98debf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame of model performance\n",
    "performance = pd.DataFrame(columns=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74fdc2-4a00-47b9-bc93-deb858801aa5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b3e88-861e-4b21-a811-7754f1611494",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the model\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "# Define the pipeline\n",
    "pipe_lr = Pipeline([\n",
    "    ('data_preprocessing', data_preprocessor),\n",
    "    ('logistic_regression', model_lr)\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipe_lr.fit(X_train, \n",
    "            np.ravel(y_train))\n",
    "\n",
    "# Get number of sold predictions\n",
    "predictions_lr = pipe_lr.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "cohen_kappa_score_lr = round(cohen_kappa_score(y_test,\n",
    "                                               predictions_lr, \n",
    "                                               weights='quadratic'), 2)\n",
    "\n",
    "print('Cohen Kappa Score: {}'.format(cohen_kappa_score_lr))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe3598-3ebe-4459-9cf6-8c0f5672c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['Logistic Regression'] = [cohen_kappa_score_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364825e7-c440-490d-91cd-86b7753724fe",
   "metadata": {},
   "source": [
    "## Logistic Regression with Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d9308-9309-4937-bf3b-9c62033d27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the a Stratified K-fold Shuffle Splitter\n",
    "stratified_kfold = StratifiedShuffleSplit(n_splits=8,\n",
    "                                          test_size=.3, \n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6c078-cd8a-42bb-bce1-12a070811cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the model\n",
    "model_lr_cv = LogisticRegression()\n",
    "\n",
    "# Define the pipeline\n",
    "pipe_lr_cv = Pipeline([\n",
    "    ('data_preprocessing', data_preprocessor),\n",
    "    ('logistic_regression', model_lr_cv)\n",
    "])\n",
    "\n",
    "# Initialise empty lists for metrics\n",
    "cohen_kappa_score_lr_cv_list = []\n",
    "\n",
    "# Fetch the folds\n",
    "for fold, (train_index, validation_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "\n",
    "    # Split the data\n",
    "    X_train = X.loc[train_index]\n",
    "    X_validation = X.loc[validation_index]\n",
    "    y_train = y.loc[train_index]\n",
    "    y_validation = y.loc[validation_index]\n",
    "\n",
    "    # Fit the estimator\n",
    "    pipe_lr_cv.fit(X_train, \n",
    "                   np.ravel(y_train))\n",
    "\n",
    "    # Predictions\n",
    "    predictions_lr_cv = pipe_lr_cv.predict(X_validation)\n",
    "\n",
    "    # Compute metrics\n",
    "    cohen_kappa_score_lr_cv_fold = round(cohen_kappa_score(y_validation,\n",
    "                                                      predictions_lr_cv,\n",
    "                                                      weights='quadratic'), 2)\n",
    "\n",
    "    print('---- Fold {} ----'.format(fold))\n",
    "    print('Cohen Kappa Score: {}'.format(cohen_kappa_score_lr_cv_fold))\n",
    "    print('\\n')\n",
    "\n",
    "    # Append mentrics to the corresponding list\n",
    "    cohen_kappa_score_lr_cv_list.append(cohen_kappa_score_lr_cv_fold)\n",
    "\n",
    "# Compute metrics average\n",
    "cohen_kappa_score_lr_cv = round(np.mean(cohen_kappa_score_lr_cv_list), 2)\n",
    "\n",
    "print('Cohen Kappa Score: {}'.format(cohen_kappa_score_lr_cv))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9610e8-f1f6-4486-ba7c-c93c4cda3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['Logistic Regression with Stratified K-Fold'] = [cohen_kappa_score_lr_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3ceb1-4930-4a19-9630-401ba5f75a3b",
   "metadata": {},
   "source": [
    "## XGBoost Classifier with Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a07267-2c37-4810-8a1c-4d05ee6ca8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the model\n",
    "model_xgb_cv = XGBClassifier(n_estimators=500)\n",
    "\n",
    "# Define the pipeline\n",
    "pipe_xgb_cv = Pipeline([\n",
    "    ('data_preprocessing', data_preprocessor),\n",
    "    ('xgb_classifier', model_xgb_cv)\n",
    "])\n",
    "\n",
    "# Initialise empty lists for metrics\n",
    "cohen_kappa_score_xgb_cv_list = []\n",
    "\n",
    "# Fetch the folds\n",
    "for fold, (train_index, validation_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "\n",
    "    # Split the data\n",
    "    X_train = X.loc[train_index]\n",
    "    X_validation = X.loc[validation_index]\n",
    "    y_train = y.loc[train_index]\n",
    "    y_validation = y.loc[validation_index]\n",
    "    \n",
    "    # Fit the estimator\n",
    "    pipe_xgb_cv.fit(X_train,\n",
    "                    y_train)\n",
    "\n",
    "    # Predictions\n",
    "    predictions_xgb_cv = pipe_xgb_cv.predict(X_validation)\n",
    "\n",
    "    # Compute metrics\n",
    "    cohen_kappa_score_xgb_cv_fold = round(cohen_kappa_score(y_validation,\n",
    "                                                            predictions_xgb_cv,\n",
    "                                                            weights='quadratic'), 2)\n",
    "\n",
    "    print('---- Fold {} ----'.format(fold))\n",
    "    print('Fold Cohen Kappa Score: {}'.format(cohen_kappa_score_xgb_cv_fold))\n",
    "    print('\\n')\n",
    "\n",
    "    # Append mentrics to the corresponding list\n",
    "    cohen_kappa_score_xgb_cv_list.append(cohen_kappa_score_xgb_cv_fold)\n",
    "\n",
    "# Compute metrics average\n",
    "cohen_kappa_score_xgb_cv = round(np.mean(cohen_kappa_score_xgb_cv_list), 2)\n",
    "\n",
    "print('Cohen Kappa Score: {}'.format(cohen_kappa_score_xgb_cv))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aac915-2981-4446-9297-340053540ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['XGBoost with Stratified K-Fold'] = [cohen_kappa_score_xgb_cv]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe31e0-b31d-4ab3-9031-3ba5ea310fa2",
   "metadata": {},
   "source": [
    "## XGBoost Classifier with Stratified K-Fold and Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98486b3-5de0-4c94-8783-e360b4cdcee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Hyperparamters space for XGBoost\n",
    "hyperparameter_space_xgb_cv_hp = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 800, 1800, 100),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 18, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.1, 0.01)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832fdd1-3e8e-40ec-92dd-fc84540a9e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the a Stratified K-fold Shuffle Splitter\n",
    "stratified_kfoldxgb_cv_hp = StratifiedShuffleSplit(n_splits=3,\n",
    "                                                   test_size=.3,\n",
    "                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa030827-4961-4bc2-9b69-bcbdcc538ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective_xgb_cv_hp(hyperparameter_space: dict):\n",
    "    \n",
    "    print('Hyperparameters')\n",
    "    print('n_estimators: {}'.format(int(hyperparameter_space['n_estimators'])))\n",
    "    print('max_depth: {}'.format(int(hyperparameter_space['max_depth'])))\n",
    "    print('learning_rate: {}'.format(hyperparameter_space['learning_rate']))\n",
    "        \n",
    "    # Define the model\n",
    "    model_xgb_cv_hp = XGBClassifier(n_estimators=int(hyperparameter_space['n_estimators']), \n",
    "                                    max_depth=int(hyperparameter_space['max_depth']), \n",
    "                                    learning_rate=hyperparameter_space['learning_rate'])\n",
    "\n",
    "    # Define the pipeline\n",
    "    pipe_xgb_cv_hp = Pipeline([\n",
    "        ('data_preprocessing', data_preprocessor),\n",
    "        ('xgb_classifier', model_xgb_cv_hp)\n",
    "    ])\n",
    "    \n",
    "    # Initialise empty lists for metrics\n",
    "    cohen_kappa_score_xgb_cv_hp_list = []\n",
    "\n",
    "    # Fetch the folds\n",
    "    for fold, (train_index, validation_index) in enumerate(stratified_kfoldxgb_cv_hp.split(X, y)):\n",
    "        \n",
    "        # Split the data\n",
    "        X_train = X.loc[train_index]\n",
    "        X_validation = X.loc[validation_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        y_validation = y.loc[validation_index]\n",
    "\n",
    "        # Fit the estimator\n",
    "        pipe_xgb_cv_hp.fit(X_train,\n",
    "                           y_train)\n",
    "\n",
    "        # Predictions\n",
    "        predictions_xgb_cv_hp = pipe_xgb_cv_hp.predict(X_validation)\n",
    "\n",
    "        # Compute metrics\n",
    "        cohen_kappa_score_xgb_cv_hp_fold = round(cohen_kappa_score(y_validation,\n",
    "                                                                   predictions_xgb_cv_hp,\n",
    "                                                                   weights='quadratic'), 2)\n",
    "\n",
    "        # Append mentrics to the corresponding list\n",
    "        cohen_kappa_score_xgb_cv_hp_list.append(cohen_kappa_score_xgb_cv_hp_fold)\n",
    "\n",
    "\n",
    "    # Compute metrics average\n",
    "    cohen_kappa_score_xgb_cv_hp = round(np.mean(cohen_kappa_score_xgb_cv_hp_list), 2)\n",
    "    \n",
    "    print('Cohen Kappa Score: {}'.format(cohen_kappa_score_xgb_cv_hp))\n",
    "    \n",
    "    return {'loss': -cohen_kappa_score_xgb_cv_hp, 'status': STATUS_OK }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f914d1-d559-43b1-91a2-62f9b4b22d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform the Hyperparameters Tuning\n",
    "parameters_xgb_cv_hyperopt = fmin(fn=objective_xgb_cv_hp,\n",
    "                                  space=hyperparameter_space_xgb_cv_hp, \n",
    "                                  algo=tpe.suggest, \n",
    "                                  max_evals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619fccdf-e891-4a24-8049-529505a1475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the model\n",
    "model_xgb_cv_hp = XGBClassifier(n_estimators=int(parameters_xgb_cv_hyperopt['n_estimators']), \n",
    "                                max_depth=int(parameters_xgb_cv_hyperopt['max_depth']), \n",
    "                                learning_rate=parameters_xgb_cv_hyperopt['learning_rate'])\n",
    "\n",
    "# Define the pipeline\n",
    "pipe_xgb_cv_hp = Pipeline([\n",
    "    ('data_preprocessing', data_preprocessor),\n",
    "    ('xgb_classifier', model_xgb_cv_hp)\n",
    "])\n",
    "\n",
    "# Initialise empty lists for metrics\n",
    "cohen_kappa_score_xgb_cv_hp_list = []\n",
    "\n",
    "# Fetch the folds\n",
    "for fold, (train_index, validation_index) in enumerate(stratified_kfold.split(X, y)):\n",
    "\n",
    "    # Split the data\n",
    "    X_train = X.loc[train_index]\n",
    "    X_validation = X.loc[validation_index]\n",
    "    y_train = y.loc[train_index]\n",
    "    y_validation = y.loc[validation_index]\n",
    "    \n",
    "    # Fit the estimator\n",
    "    pipe_xgb_cv_hp.fit(X_train,\n",
    "                       y_train)\n",
    "\n",
    "    # Predictions\n",
    "    predictions_xgb_cv_hp = pipe_xgb_cv_hp.predict(X_validation)\n",
    "\n",
    "    # Compute metrics\n",
    "    cohen_kappa_score_xgb_cv_hp_fold = round(cohen_kappa_score(y_validation,\n",
    "                                                               predictions_xgb_cv_hp,\n",
    "                                                               weights='quadratic'), 2)\n",
    "\n",
    "    print('---- Fold {} ----'.format(fold))\n",
    "    print('Fold Cohen Kappa Score: {}'.format(cohen_kappa_score_xgb_cv_hp_fold))\n",
    "    print('\\n')\n",
    "\n",
    "    # Append mentrics to the corresponding list\n",
    "    cohen_kappa_score_xgb_cv_hp_list.append(cohen_kappa_score_xgb_cv_hp_fold)\n",
    "\n",
    "# Compute metrics average\n",
    "cohen_kappa_score_xgb_cv_hp = round(np.mean(cohen_kappa_score_xgb_cv_hp_list), 2)\n",
    "\n",
    "print('Cohen Kappa Score: {}'.format(cohen_kappa_score_xgb_cv_hp))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbe572-9cb0-4506-a041-436484dfd26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update 'performance' DataFrame\n",
    "performance.loc['XGBoost with Stratified K-Fold and Hyperopt'] = [cohen_kappa_score_xgb_cv_hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ac1cf-cdfa-472a-9bdf-57dba7e67e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce798d-a6a9-4fc4-b200-30bd5483ad98",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034ad4d-d968-4bd4-909a-053510930a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot 'barplot' of 'fare' for 'embark_town'\n",
    "ax = sns.barplot(data=performance, \n",
    "                 x=performance.index.tolist(), \n",
    "                 y='Cohen Kappa Score')\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Models Comparison', \n",
    "             fontsize=20, \n",
    "             fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e1e30-60e5-4e79-8369-6088312a3e55",
   "metadata": {},
   "source": [
    "# Model Explanability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca600d-8dcb-4efc-bd3a-9d37b36234eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the feature importance\n",
    "feature_importance = sorted(list(zip(pipe_xgb_cv_hp.feature_names_in_,\n",
    "                                     pipe_xgb_cv_hp['xgb_classifier'].feature_importances_)),\n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Transform it into a DataFrame\n",
    "feature_importance_df = pd.DataFrame(feature_importance,\n",
    "                                     columns= ['Feature', 'Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc69f3c-2b4c-483b-a208-9fb44af5b5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the feature importance\n",
    "ax = sns.barplot(data=feature_importance_df, \n",
    "                 x='Feature', \n",
    "                 y='Importance')\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Feature Importance', \n",
    "             fontsize=20, \n",
    "             fontweight='bold')\n",
    "\n",
    "plt.xticks(fontsize=8, \n",
    "           rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ae283-0258-4b3a-a9f3-a3f63beeccde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
